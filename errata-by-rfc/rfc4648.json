[
  {
    "errata_id": "2837",
    "doc-id": "RFC4648",
    "errata_status_code": "Verified",
    "errata_type_code": "Editorial",
    "section": "16.2",
    "orig_text": "http://zgp.org/pipermail/p2p-hackers/2001-September/000315.html",
    "correct_text": "http://zgp.org/pipermail/p2p-hackers/2001-September/000316.html",
    "notes": "The same \"off by one\" issue was already present in RFC 3548 (obsoleted by RFC 4648).  The archived article 315 has another author.  Articles 316 and 319 are from the author noted in the RFCs, belong to a discussion of \"web-safe base64\" formats (incl. hex. + base32 alternatives), and specify the relevant base64 modification:\r\n\r\n316 is shorter than 319, and nearer to the erroneous 315, so that was likely the intended article.",
    "submit_date": "2011-06-15",
    "submitter_name": "Frank Ellermann",
    "verifier_id": "121",
    "verifier_name": "Peter Saint-Andre",
    "update_date": "2019-09-10 09:09:03"
  },
  {
    "errata_id": "4889",
    "doc-id": "RFC4648",
    "errata_status_code": "Reported",
    "errata_type_code": "Technical",
    "section": "6",
    "orig_text": "When fewer than 40 input bits\r\nare available in an input group, bits with value zero are added (on\r\nthe right) to form an integral number of 5-bit groups.",
    "correct_text": "When fewer than 40 input bits\r\nare available in an input group, bits with value zero are added (on\r\nthe right) to form an integral number of 8-bit groups.",
    "notes": "8-bit instead of 5-bit.\r\nWhat follows the correction clearly shows that the final input group must be 8, 16, 24, 32 or 40 bit long, that is, a multiple of 8, not of 5.\r\nAlso examples of commonly-used Base32 encoders/decoders seem to show this behaviour.\r\nAlso, I would not say \"When fewer than 40 input bits are available in an input group\" but rather \"When fewer than 40 input bits are available in the final input group\", to better clarify and not to change the subject ambiguously, unless this is intentionally applicable to any input lot.",
    "submit_date": "2016-12-14",
    "submitter_name": "Umberto Rustichelli",
    "verifier_id": "99",
    "verifier_name": null,
    "update_date": "2019-09-10 09:09:03"
  },
  {
    "errata_id": "5855",
    "doc-id": "RFC4648",
    "errata_status_code": "Reported",
    "errata_type_code": "Editorial",
    "section": "10.",
    "orig_text": "10.  Test Vectors\r\n\r\n   BASE64(\"\") = \"\"\r\n\r\n   BASE64(\"f\") = \"Zg==\"\r\n\r\n   ...",
    "correct_text": null,
    "notes": "TL;DR: Test Vectors section should specify the character encoding (ASCII/UTF-8) of the _character_ sequences used to represent input-data _octet_ sequences.\r\n\r\nThe input to a Base 64/-32/-16 encoding operation is sequence of _octets_.\r\n\r\nHowever, the test vector expressions use sequences of _characters_ to represent input _octet_ sequences.\r\n\r\nThat's a type mismatch (characters where octets are needed), and although it's pretty obvious that the strings were meant to represent octet sequences, there's no mention the the intended character encoding isn't, say, EBCDIC.  \r\n\r\nSome possible fixes:\r\n1) The text should specify the character encoding (ASCII/UTF-8) to be used to interpret the character sequences as input octet sequences.\r\n2) The input octet sequences should be represented with a more direct (encoding-independent) representation of octets (e.g., \"0x48, 0x69\".).",
    "submit_date": "2019-09-06",
    "submitter_name": "Daniel Barclay",
    "verifier_id": "99",
    "verifier_name": null,
    "update_date": "2019-09-10 09:09:03"
  }
]
